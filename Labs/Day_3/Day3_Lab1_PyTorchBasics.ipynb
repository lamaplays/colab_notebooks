{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KamP67nRt-Ko"
      },
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRn1N6ZuHHg"
      },
      "source": [
        "#**Lab: Pytorch Basics**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZXwf7gKK_Ia"
      },
      "source": [
        "## **What is Pytorch?** <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/PyTorch_logo_icon.svg/500px-PyTorch_logo_icon.svg.png\" width=\"4%\">\n",
        "\n",
        "\n",
        "**PyTorch** is an open-source deep learning framework that allows us to build and train neural networks using **tensors** and **automatic differentiation**.  \n",
        "It provides simple, flexible tools to define models, compute gradients using backpropagation, and optimize parameters efficiently.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMLes6srWwMe"
      },
      "source": [
        "## üì¶ **Tensors in PyTorch**\n",
        "\n",
        "A **tensor** is the main data structure in PyTorch.  \n",
        "It is similar to a NumPy array, but can run on both CPUs and GPUs.\n",
        "\n",
        "Tensors are used to represent: input data, model parameters, and model outputs\n",
        "\n",
        "### üîπ Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_R5-1UJaw0w",
        "outputId": "6bc5de87-bc36-4580-fcc1-06b2d6eb71fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor([1., 2., 3.])\n",
            "y: tensor([0.3548, 0.3962, 0.4785])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.randn(3)\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1boO-_nua7dB"
      },
      "source": [
        "### üîπ Tensor Shapes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDn9esxa_o_",
        "outputId": "4a5e910b-0e78-4ec2-e013-968504777d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of x:\", x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfrk3ELobLIP"
      },
      "source": [
        "### üîπ Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Krsxjc3bYqo",
        "outputId": "93e63ace-c817-4889-e52e-50e2b45f9f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Addition: tensor([5., 7., 9.])\n",
            "Multiplication: tensor([ 4., 10., 18.])\n",
            "Matrix multiplication result shape: torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "# Element-wise operations\n",
        "print(\"Addition:\", a + b)\n",
        "print(\"Multiplication:\", a * b)\n",
        "\n",
        "# Matrix multiplication\n",
        "A = torch.randn(2, 3)\n",
        "B = torch.randn(3, 2)\n",
        "C = A @ B\n",
        "\n",
        "print(\"Matrix multiplication result shape:\", C.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rYObkabicO"
      },
      "source": [
        "\n",
        "\n",
        "> See! just like Numpy Arrays, but more powerful!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOtVHO3WY_-"
      },
      "source": [
        "---\n",
        "## üìä **Data Representation in Deep Learning**\n",
        "\n",
        "The way data is represented depends on whether it is **structured (tabular)** or **unstructured (images)**.\n",
        "\n",
        "### üîπ1Ô∏è‚É£ **Tabular Data (Structured Data)**\n",
        "Tabular data consists of rows and columns.\n",
        "\n",
        "Each row represents a sample and each column represents a feature.\n",
        "\n",
        "- Represented as a **2D tensor**\n",
        "- Shape: `(batch_size, number_of_features)`\n",
        "- Commonly used for tasks like regression and classification\n",
        "\n",
        "Example:\n",
        "- Features: age, salary, debt  \n",
        "- Tensor shape: `(N, 3)`\n",
        "\n",
        "### üîπ2Ô∏è‚É£ **Image Data (Unstructured Data)**\n",
        "Image data is unstructured and contains spatial information.\n",
        "\n",
        "- Represented as a **4D tensor**\n",
        "- Shape: `(batch_size, channels, height, width)`\n",
        "- Channels represent color information:\n",
        "  - Grayscale ‚Üí 1 channel\n",
        "  - RGB ‚Üí 3 channels\n",
        "\n",
        "Example:\n",
        "- RGB image of size 224√ó224  \n",
        "- Tensor shape: `(N, 3, 224, 224)`\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27NITm3aWla9"
      },
      "source": [
        "## üìå **How to Change Dimensions in PyTorch?**\n",
        "\n",
        "Manipulating tensor shapes is essential in deep learning. PyTorch provides several functions to modify tensor dimensions.\n",
        "\n",
        "### **üîπ 1Ô∏è‚É£ Flatten**\n",
        "- Converts **any shape** to `(batch_size, features)`.\n",
        "- **Example:**  \n",
        "  `(batch_size, channels, height, width) ‚Üí (batch_size, features)`\n",
        "\n",
        "### **üîπ 2Ô∏è‚É£ Squeeze**\n",
        "- **Removes dimensions** with size `1`.\n",
        "- **Example:**  \n",
        "  `(1, 32, 3, 28, 28) ‚Üí (32, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 3Ô∏è‚É£ Unsqueeze**\n",
        "- **Adds a dimension** with size `1` at a specified position.\n",
        "- **Example:**  \n",
        "  `(3, 28, 28) ‚Üí (1, 3, 28, 28)`\n",
        "\n",
        "### **üîπ 4Ô∏è‚É£ View (works similar to reshape)**\n",
        "- **Reshapes a tensor freely** while maintaining the same number of elements.\n",
        "- **Example:**  \n",
        "  `(32, 3, 28, 28) ‚Üí view(-1, 3*28*28) ‚Üí (32, 3*28*28)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY0z_-JwRYWk",
        "outputId": "ec362895-9176-491b-d51e-d9e63d9b1e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flatten: torch.Size([32, 2352])\n",
            "Squeeze: torch.Size([3, 28, 28])\n",
            "Unsqueeze: torch.Size([1, 3, 28, 28])\n",
            "View: torch.Size([32, 2352])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1Ô∏è‚É£ Flatten - Convert any shape to (batch_size, features)\n",
        "x = torch.randn(32, 3, 28, 28)\n",
        "x_flat = x.flatten(start_dim=1)\n",
        "print(\"Flatten:\", x_flat.shape)  # (32, 2352) 3*28*28 = 2352\n",
        "\n",
        "# 2Ô∏è‚É£ Squeeze - Remove dimensions with size 1\n",
        "x = torch.randn(1, 3, 28, 28)\n",
        "x_sq = x.squeeze()\n",
        "print(\"Squeeze:\", x_sq.shape)  # (3, 28, 28)\n",
        "\n",
        "# 3Ô∏è‚É£ Unsqueeze - Add a new dimension of size 1\n",
        "x = torch.randn(3, 28, 28)\n",
        "x_unsq = x.unsqueeze(0)\n",
        "print(\"Unsqueeze:\", x_unsq.shape)  # (1, 3, 28, 28)\n",
        "\n",
        "# 4Ô∏è‚É£ View - Reshape freely while keeping same number of elements\n",
        "x = torch.randn(32, 28, 28, 3)\n",
        "x_view = x.view(32, -1)  # Flatten all except batch\n",
        "print(\"View:\", x_view.shape)  # (32, 28*28*3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q98MVwNxvNwL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkrCEfnNborH"
      },
      "source": [
        "## üìå **Changing Data Type or Moving Data/Model to CPU/GPU**  \n",
        "\n",
        "PyTorch allows you to **change the datatype** of a tensor and **move it between CPU and GPU** using `.to()`.  \n",
        "\n",
        "\n",
        "### üîπ **Change Datatype**\n",
        "Use `.to(dtype)` to convert a tensor's data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwAQnY7HWYlG",
        "outputId": "090a2dac-fd3b-46c8-cf81-28dbeb5a00c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "torch.float16\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a float32 tensor\n",
        "x = torch.tensor([1.2, 2.3, 3.4], dtype=torch.float32)\n",
        "print(x.dtype)  # Output: torch.float32\n",
        "\n",
        "# Convert to float16\n",
        "x_half = x.to(torch.float16)\n",
        "print(x_half.dtype)  # Output: torch.float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MOJ8tx0ceVL"
      },
      "source": [
        "### üîπ **Move Tensors to GPU (if available)**\n",
        "**GPUs are faster and more efficient** in most cases when training or inferencing deep learning models.\n",
        "\n",
        "Use `.to(device)` to move a tensor to GPU for faster computation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iv00vultxnB",
        "outputId": "4ada2c54-8d8d-4fe1-da07-6775b53aa5ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Automatically select CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create a tensor and move it to GPU\n",
        "x_gpu = x.to(device)\n",
        "print(x_gpu.device)  # Output: cuda:0 (if GPU is available) or cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqEVOLXed3ut"
      },
      "source": [
        "Note: When training a model, always move BOTH the model and data to the same device. Otherwise, you will get an error like this:\n",
        "\n",
        "`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8DN_nVlUbod"
      },
      "source": [
        "## **üìå PyTorch Workflow Organization**\n",
        "\n",
        "### **It consists of 4 main components:**\n",
        "1Ô∏è‚É£ **Dataset Class**  \n",
        "- Handles loading and preprocessing data.  \n",
        "- Converts raw data (e.g., images, CSVs) into model-ready tensors.  \n",
        "\n",
        "2Ô∏è‚É£ **Model Class**  \n",
        "- Defines the architecture of your neural network (e.g., layers, activations).  \n",
        "\n",
        "3Ô∏è‚É£ **Training Loop**  \n",
        "- Updates model weights using backpropagation and optimizers.  \n",
        "- Computes the loss for every batch and adjusts the parameters to minimize it.  \n",
        "\n",
        "4Ô∏è‚É£ **Validation Loop**  \n",
        "- Evaluates the model's performance on a validation set.  \n",
        "- Does not update weights but computes metrics like accuracy or loss.  \n",
        "\n",
        "\n",
        "\n",
        "### **üìå Note:**\n",
        "All the labs will follow this structure. You will just modify the content for different tasks, such as changing datasets, architectures, or loss functions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXG9aSXCYaza"
      },
      "source": [
        "## 1Ô∏è‚É£ **Dataset Class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOwm0-zsulwK"
      },
      "source": [
        "In PyTorch, a **Dataset Class** is responsible for transforming raw data into samples that are ready to be used by a model.  \n",
        "Each sample returned consists of:\n",
        "- An **input** (features or image)\n",
        "- Its corresponding **label**  \n",
        "\n",
        "\n",
        "\n",
        "## üîπ For Tabular Data (Using `TensorDataset`)\n",
        "\n",
        "When working with **tabular data** (e.g., CSV files already converted to tensors), we can use\n",
        "`TensorDataset` to pair input features with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNlgbwZPnD6H",
        "outputId": "9b31d49e-1783-4d42-beff-43809ed7426d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of one sample: torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)# long if classification\n",
        "\n",
        "# TensorDataset pairs input features (X) with their corresponding labels (y)\n",
        "# Each item in the dataset is returned as (X[i], y[i])\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Access a single sample from the dataset\n",
        "# This helps verify the shape of one data sample\n",
        "first_sample, _ = train_dataset[0]\n",
        "print(f\"Shape of one sample: {first_sample.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMPiHVpcxYt5"
      },
      "source": [
        "## üîπ For Image Data (Using Built-in Datasets)\n",
        "\n",
        "In PyTorch, image datasets can be:\n",
        "- **Built-in datasets** provided by PyTorch (e.g., MNIST, CIFAR-10)\n",
        "- **Custom datasets** created for data that is not provided in a ready-made format\n",
        "\n",
        "In **Stage 2**, we'll use **built-in datasets**\n",
        "\n",
        "In **Stage 3**, we'll create **custom Dataset classes** for our own image data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCinzfXNyUON",
        "outputId": "ae77faca-22e6-452a-b3bb-3482c9160e4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 18.0MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 481kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 7.54MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Image shape: torch.Size([1, 28, 28])\n",
            "Label: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# Training dataset\n",
        "train_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=True,            # Use training data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# Testing dataset\n",
        "test_dataset = MNIST(\n",
        "    root='./datasets',     # Dataset storage path\n",
        "    train=False,           # Use test data\n",
        "    transform=to_tensor,   # Convert images to tensors\n",
        "    download=True          # Download if not available\n",
        ")\n",
        "\n",
        "# print one sample from the dataset\n",
        "# Each sample consists of an image tensor and its label\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "\n",
        "print(f\"\\n Image shape: {sample_image.shape}\")  # (1, 28, 28)\n",
        "print(f\"Label: {sample_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5WZp8HJ6fK"
      },
      "source": [
        "\n",
        "Right now, our **Dataset Class** loads **one sample at a time** when we call:\n",
        "```python\n",
        "sample_image, sample_label = train_dataset[0]  # Loads only one sample\n",
        "```\n",
        "‚úÖ **That‚Äôs great for understanding**, but when training a model, we need to process **multiple samples at once** for efficiency.\n",
        "\n",
        "‚ùå **Problem**: We need batches, not single samples.  \n",
        "‚úÖ **Solution**: We use `DataLoader` to handle batching automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CEW3kknM6t3"
      },
      "source": [
        "## üìå **What are DataLoaders ?**\n",
        "\n",
        "<img src=\"https://i.imgur.com/aHE3lnE.png\" width=\"70%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8GKnrdjFPtH"
      },
      "source": [
        "\n",
        "A **DataLoader** is a PyTorch utility that takes a Dataset and does:\n",
        "- **Batching**: Groups multiple samples together for faster processing.\n",
        "- **Shuffling**: Randomizes data order to improve training.\n",
        "- **Multi-threading**: Loads data efficiently in parallel.\n",
        "\n",
        "| **Argument**     | **Description** |\n",
        "|-----------------|---------------|\n",
        "| `dataset` | The dataset object (e.g., `train_dataset`) |\n",
        "| `batch_size` | Number of samples per batch (e.g., `32`) |\n",
        "| `shuffle` | Whether to **randomly shuffle** data each epoch (`True` = better for training) |\n",
        "| `num_workers` | Number of parallel **CPU workers** to load data faster |\n",
        "| `collate_fn` | A function to **customize how data is stacked** (useful when data has variable sizes) |\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qivcbu_CNXfh",
        "outputId": "fa394753-258e-4f79-8adf-6575b0d6b238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training batch input shape: torch.Size([32, 1, 28, 28])\n",
            "Training batch labels shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoader for training data\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2 #how many slaves (cpu,gpu) preparing for the next batch\n",
        ")\n",
        "# DataLoader for test/validation data\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False, # data must stay the same\n",
        "    num_workers=2\n",
        ")\n",
        "# Get the first batch from the training DataLoader\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f\"Training batch input shape: {X_batch.shape}\")\n",
        "print(f\"Training batch labels shape: {y_batch.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKlCp-MvZVt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU57FGt_Ykoj"
      },
      "source": [
        "## 2Ô∏è‚É£ **Model Class**\n",
        "\n",
        "In PyTorch, `nn.Linear(in_features, out_features)`\n",
        "\n",
        "creates a **fully connected (dense) layer** that applies a linear transformation:\n",
        "\n",
        "$y = xW^T + b$\n",
        "\n",
        "\n",
        "- **`in_features`**: number of input features  \n",
        "- **`out_features`**: number of neurons (outputs) in the layer  \n",
        "- The layer automatically creates learnable **weights** and **bias**.\n",
        "\n",
        "‚úÖ Example: a layer that takes 3 input features and outputs 1 value:\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42PESt1sUw0",
        "outputId": "b85c1621-2c9f-41fa-abbc-70196de8022b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([4, 3])\n",
            "Output shape: torch.Size([4, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a linear layer: 3 input features -> 1 output\n",
        "linear = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "# Example input: batch of 4 samples, each with 3 features\n",
        "x = torch.randn(4, 3)\n",
        "\n",
        "# Forward through the layer\n",
        "y = linear(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)   # torch.Size([4, 3])\n",
        "print(\"Output shape:\", y.shape)  # torch.Size([4, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNCHp3ihvl6s"
      },
      "source": [
        "### **üìå Key Components of Model Class:**\n",
        "####1Ô∏è‚É£ **Define Layers (`__init__` method):**  \n",
        "\n",
        "Inside the `__init__` method, we define **what the neural network looks like**. This includes:\n",
        "\n",
        "- **Number of layers**  \n",
        "  How many linear (`nn.Linear`) layers the model has (depth of the network).\n",
        "\n",
        "- **Hidden layer sizes**  \n",
        "  How many neurons each hidden layer contains.\n",
        "\n",
        "- **Activation functions**  \n",
        "  Activation functions introduce **non-linearity**, allowing the network to learn complex patterns.\n",
        "  - Common choice for hidden layers: **ReLU**\n",
        "\n",
        "- **Output activation function**  \n",
        "  The activation used at the final layer depends on the task:\n",
        "  - **Binary classification** ‚Üí `Sigmoid`\n",
        "  - **Multiclass classification** ‚Üí `Softmax`\n",
        "  - **Regression** ‚Üí No activation (linear output)\n",
        "\n",
        "üìå **Important:**  \n",
        "Hidden layers usually use ReLU, while the **output layer activation is task-dependent**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWfyCtXWsTgF"
      },
      "source": [
        "#### 2Ô∏è‚É£ **Forward Pass (`forward` method):**\n",
        "\n",
        "The `forward()` method defines **how the input data flows through the model** to produce the final output.\n",
        "\n",
        "- The input tensor is passed through each layer **in order**.\n",
        "- Activation functions are applied after linear layers to introduce **non-linearity**.\n",
        "- The final layer produces the model‚Äôs prediction.\n",
        "\n",
        "üìå **Note:**  \n",
        "During training, PyTorch automatically tracks all operations in the `forward()` method to compute gradients during backpropagation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk6qfrKJK88F"
      },
      "source": [
        "‚úÖ **Example: One neural network layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmUbfIKiZc8X"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IAkZWzDOYGaiu3e47rEMgQ.png\" width=\"60%\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opi3_J4dE_pT"
      },
      "outputs": [],
      "source": [
        "class NN1Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "\n",
        "    super(NN1Layer, self).__init__()\n",
        "    # input_dim = num of features, Output for binary classification is 1\n",
        "    self.layer_1 = nn.Linear(input_dim, 1) #the parameter 1 define what task we are going to work with\n",
        "\n",
        "    # output activation function\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, x):\n",
        "    z = self.layer_1(x)\n",
        "    a = self.sigmoid(z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLXie4eWLSjd"
      },
      "source": [
        "‚úÖ **Example: Two neural network layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLPIVOoIhOhv"
      },
      "source": [
        "\n",
        "<img src=\"https://miro.medium.com/v2/0*GZrkL6Lqt9dIAJ61.jpg\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87V4-6vDFxlM"
      },
      "outputs": [],
      "source": [
        "class NN2Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "\n",
        "        super(NN2Layer, self).__init__()\n",
        "        # input_dim = num of features, hidden_dim = num of neurons\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # hidden_dim = num of neurons, Output for binary classification is 1\n",
        "        self.layer2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        # non-linearity activation function\n",
        "        self.relu = nn.ReLU()\n",
        "        # output activation function\n",
        "        self.sigmoid = nn.Sigmoid() # SIGMOID ONLY USED THE AT END ALWAYS\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self, x):\n",
        "        z1 = self.layer1(x)\n",
        "        a1 = self.relu(z1)\n",
        "        z2 = self.layer2(a1)\n",
        "        a2 = self.sigmoid(z2)\n",
        "        return a2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slEZs4vBe1dJ"
      },
      "source": [
        "\n",
        "\n",
        "> We can instantiate the model and print it to see the architecture, layers, and total number of trainable parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKrJiWQTdgYZ",
        "outputId": "b64626a0-a679-4d53-aceb-c6ee19f5fce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Architecture:\n",
            "\n",
            "NN2Layer(\n",
            "  (layer1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (layer2): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Total trainable parameters: 19\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model\n",
        "input_dim = 4     # number of input features\n",
        "hidden_dim = 3    # number of hidden neurons\n",
        "\n",
        "model = NN2Layer(input_dim, hidden_dim) # count the number of wieghts 4*3 +3+3*1 +1 =19 (+1 and +3 are the biases, one for each out features)\n",
        "\n",
        "# Print the model architecture\n",
        "print(\"Model Architecture:\\n\")\n",
        "print(model)\n",
        "\n",
        "# Calculate the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYO9UOyvWYR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o42xnLsEYr8D"
      },
      "source": [
        "## 3Ô∏è‚É£ **Training Loop**\n",
        "\n",
        "The **training loop** is responsible for **updating the model's weights** so that it learns to minimize the loss function.\n",
        "\n",
        "### üß© **Parameters**\n",
        "\n",
        "- **`model`** ‚Äì The neural network to be trained.  \n",
        "- **`optimizer`** ‚Äì Updates model parameters (e.g., SGD, Adam).  \n",
        "- **`criterion`** ‚Äì Loss function, depends on the task.  \n",
        "- **`train_loader`** ‚Äì PyTorch `DataLoader` that provides batches of training data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfanJzrdnFA_"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to the selected device\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch) #y_batch = y_hat\n",
        "\n",
        "        # Backward pass & optimization\n",
        "        optimizer.zero_grad()   # Clear previous gradients\n",
        "        loss.backward()         # Compute gradients\n",
        "        optimizer.step()        # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Average loss over all batches\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FYUwAxlpXzY"
      },
      "source": [
        "###üìå **For criterions (Loss Functions)**:\n",
        "Different tasks require different loss functions\n",
        "- Linear Regression ‚Üí `nn.MSELoss()`  \n",
        "- Binary classification ‚Üí `nn.BCELoss()`  \n",
        "- Multiclass classification ‚Üí `nn.CrossEntropyLoss()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDYXDDeNqwCY"
      },
      "source": [
        "####1Ô∏è‚É£ `nn.MSELoss()`\n",
        "- `MSELoss` expects **continuous values** (regression).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDWNgCK2sCDo",
        "outputId": "58ed0bf8-be98-4047-bded-ddd70cee0365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE Loss: 0.25\n"
          ]
        }
      ],
      "source": [
        "# Example predictions and targets\n",
        "y_pred = torch.tensor([[2.5], [3.0], [4.5]])\n",
        "y_true = torch.tensor([[3.0], [2.5], [5.0]])\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"MSE Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9OMs--Rs4Jk"
      },
      "source": [
        "####2Ô∏è‚É£ `nn.BCELoss()`\n",
        "- `BCELoss` expects **probabilities** between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lNu1qss7rz",
        "outputId": "89bb69ea-7ef7-46d3-f974-8d9e216fc99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary Cross Entropy Loss: 0.36354804039001465\n"
          ]
        }
      ],
      "source": [
        "# Predicted probabilities (after sigmoid)\n",
        "y_pred = torch.tensor([[0.8], [0.3], [0.6]])\n",
        "y_true = torch.tensor([[1.0], [0.0], [1.0]])\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "loss = criterion(y_pred, y_true)\n",
        "print(\"Binary Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr8bgGs6tFJi"
      },
      "source": [
        "####3Ô∏è‚É£ `nn.CrossEntropyLoss()`\n",
        "- `CrossEntropyLoss` expects **raw logits** (no Softmax needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaba4iKbta-I",
        "outputId": "51f05ce3-5771-4eec-c9c3-bb0ba359d951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross Entropy Loss: 0.450598806142807\n"
          ]
        }
      ],
      "source": [
        "# Raw model outputs (logits), shape: (batch_size, num_classes)\n",
        "logits = torch.tensor([\n",
        "    [2.0, 0.5, 1.0],\n",
        "    [0.1, 1.5, 0.3]\n",
        "])\n",
        "# True class indices\n",
        "targets = torch.tensor([0, 1])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(logits, targets)\n",
        "print(\"Cross Entropy Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UlJgjmKvjbp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Isn-l9gYyfT"
      },
      "source": [
        "\n",
        "## 4Ô∏è‚É£ **Validation Loop**\n",
        "\n",
        "The **validation loop** evaluates the model‚Äôs performance on unseen data **without updating the weights**.\n",
        "\n",
        "It is used to measure how well the model generalizes.\n",
        "\n",
        "### üß© Parameters\n",
        "\n",
        "- **`model`** ‚Äì The trained neural network to be evaluated.  \n",
        "- **`criterion`** ‚Äì Loss function used for evaluation\n",
        "- **`test_loader`** ‚Äì PyTorch `DataLoader` that provides batches of validation/test data.  \n",
        "- **`device`** ‚Äì Device used for computation (`cpu` or `cuda`).  \n",
        "\n",
        "\n",
        "üìå **Note:**  \n",
        "Gradients are disabled during validation using `torch.no_grad()` to improve efficiency and prevent weight updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxMyr159d5UW"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, test_loader, device):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            # Move batch to the selected device\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.view(-1, 1).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Binary predictions\n",
        "            predicted = (outputs > 0.5).float() #threshold\n",
        "\n",
        "            # Accuracy calculation\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(test_loader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bcKsHoLvTxk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkoj068knVPN"
      },
      "source": [
        "## **üìå Full Training Process in PyTorch**\n",
        "\n",
        "Now that you understand the **Dataset Class, Model Class, Training Loop, and Validation Loop**, it's time to put everything together into a **full training process**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUK2taqBkUyR"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zryj9VCzkaHl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOguR6wwkmlr"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT-TaJLL6isg"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# transform to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets for training and testing\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create Dataloaders to train and test data in batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Y-oPSxlJOw"
      },
      "source": [
        "### Run full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgTf7gdlOQZ",
        "outputId": "3ce0afc0-00af-4129-cebe-ea24a62bbe09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Starting Training...\n",
            "Epoch [5/50], Train Loss: 0.5033, Val Loss: 0.4893, Val Accuracy: 0.9035\n",
            "Epoch [10/50], Train Loss: 0.2352, Val Loss: 0.2549, Val Accuracy: 0.9386\n",
            "Epoch [15/50], Train Loss: 0.1410, Val Loss: 0.1643, Val Accuracy: 0.9561\n",
            "Epoch [20/50], Train Loss: 0.1111, Val Loss: 0.1297, Val Accuracy: 0.9474\n",
            "Epoch [25/50], Train Loss: 0.0915, Val Loss: 0.1127, Val Accuracy: 0.9561\n",
            "Epoch [30/50], Train Loss: 0.0765, Val Loss: 0.1032, Val Accuracy: 0.9561\n",
            "Epoch [35/50], Train Loss: 0.0670, Val Loss: 0.0972, Val Accuracy: 0.9649\n",
            "Epoch [40/50], Train Loss: 0.0831, Val Loss: 0.0932, Val Accuracy: 0.9561\n",
            "Epoch [45/50], Train Loss: 0.0577, Val Loss: 0.0909, Val Accuracy: 0.9649\n",
            "Epoch [50/50], Train Loss: 0.0542, Val Loss: 0.0885, Val Accuracy: 0.9649\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001 # size of the jumps in the step (batch)\n",
        "\n",
        "# Model, Criterion, Optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 10\n",
        "model =NN2Layer(input_dim, hidden_dim).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# Run Training\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print('Starting Training...')\n",
        "for epoch in range(num_epochs):\n",
        "    # Train one epoch\n",
        "    train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_accuracy = validate(model, criterion, test_loader, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvvMxHD4nfTs"
      },
      "source": [
        "### Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "1ftDlPPhniA6",
        "outputId": "5875bc86-88ee-4894-ada8-1d7972d6cfa0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting results\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdvSQimxq_3O"
      },
      "source": [
        "## Now you know how to use PyTorch for NNs :)\n",
        "\n",
        "\n",
        "![image.png](https://i.imgur.com/1xbDOQX.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDl5V6-7SOal"
      },
      "source": [
        "### **Contributed by: Yara Alzahrani, Mohamed Eltayeb**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}